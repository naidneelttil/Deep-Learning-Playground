{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "this is a brief attempt to use jupyter notebooks. Here I am installing everything I can need to create an NLP application. some of it is unnessesary, but were copied off of Chris's notes."
      ],
      "metadata": {
        "id": "ur58PZefTc5L"
      },
      "id": "ur58PZefTc5L"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import subprocess\n",
        "import importlib.util\n",
        "\n",
        "libraries=[\"openai\", \"nltk\", \"bs4\", \"wordcloud\", \"pathlib\", \"numpy\", \"Pillow\", \"spacy\"]\n",
        "import importlib.util\n",
        "\n",
        "for library in libraries:\n",
        "    if library == \"Pillow\":\n",
        "      spec = importlib.util.find_spec(\"PIL\")\n",
        "    else:\n",
        "      spec = importlib.util.find_spec(library)\n",
        "    if spec is None:\n",
        "      print(\"Installing library \" + library)\n",
        "      subprocess.run([\"pip\", \"install\" , library, \"--quiet\"])\n",
        "    else:\n",
        "      print(\"Library \" + library + \" already installed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUlo70p9Tupm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1726686760886,
          "user_tz": 240,
          "elapsed": 239,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "fa5a995e-e1af-4da7-9a87-c2c13a4edc66"
      },
      "id": "jUlo70p9Tupm",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Library openai already installed.\n",
            "Library nltk already installed.\n",
            "Library bs4 already installed.\n",
            "Library wordcloud already installed.\n",
            "Library pathlib already installed.\n",
            "Library numpy already installed.\n",
            "Library Pillow already installed.\n",
            "Library spacy already installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are going to download a best matching default model for the english language. and then we are going to laod that model as nlp."
      ],
      "metadata": {
        "id": "MVzp9pKShb0p"
      },
      "id": "MVzp9pKShb0p"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [],
        "id": "yBtUachMgiJB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1726686890313,
          "user_tz": 240,
          "elapsed": 14908,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "#importing and loading in scapy\n",
        "import spacy\n",
        "subprocess.run([\"python\", \"-m\" , \"spacy\", \"download\", \"en_core_web_md\"])\n",
        "nlp = spacy.load('en_core_web_md')"
      ],
      "id": "yBtUachMgiJB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "an example using our default model to tokenize."
      ],
      "metadata": {
        "id": "k9WVfOFdj1E6"
      },
      "id": "k9WVfOFdj1E6"
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('I am learning about natural language processing')\n",
        "print([ w.text for w in doc ])\n",
        "\n",
        "# here we are going to see the same sentence lemminzed. that is, each word is\n",
        "# returned to its base form if it isn't already\n",
        "print(\"------------------------------------\")\n",
        "print(\"unlemminized word vs lemminized word\")\n",
        "print(\"------------------------------------\")\n",
        "for token in doc:\n",
        "  print(token.text, token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSsvRjBtj0cm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1726688625785,
          "user_tz": 240,
          "elapsed": 263,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "384a7dcd-d14d-455c-9a64-8ae8de935f22"
      },
      "id": "FSsvRjBtj0cm",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'am', 'learning', 'about', 'natural', 'language', 'processing']\n",
            "------------------------------------\n",
            "unlemminized word vs lemminized word\n",
            "------------------------------------\n",
            "I I\n",
            "am be\n",
            "learning learn\n",
            "about about\n",
            "natural natural\n",
            "language language\n",
            "processing processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "68EjvuIOhK_u"
      },
      "id": "68EjvuIOhK_u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_qNz-hufrMC"
      },
      "id": "4_qNz-hufrMC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "testNotebook.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}